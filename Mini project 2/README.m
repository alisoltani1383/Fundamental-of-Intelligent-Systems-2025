# ğŸ§  Mini Project 2 â€“ Fundamentals of Intelligent Systems

## ğŸ“˜ Course: Fundamentals of Intelligent Systems  
**Instructor:** Dr. Aliyary  
**University:** Khajeh Nasir Toosi University of Technology  
**Semester:** Fall 2025  

---

## ğŸ‘¥ Authors
- **HamidReza Eslami** (40115563)  
- **Ali Soltani** (40119403)  

---

## ğŸ¯ Objective

The objective of this mini project is to **analyze, design, and implement intelligent learning systems** based on both **theoretical foundations** and **practical machine learning models**, with a strong focus on **Support Vector Machines (SVMs)** and **Radial Basis Function Neural Networks (RBFNNs)**.

---

## ğŸ“ Description

This project is part of **Mini Project 2** for the *Fundamentals of Intelligent Systems* course.  
It combines **mathematical derivations**, **conceptual analysis**, and **hands-on implementations** to study how intelligent systems perform classification and nonlinear function approximation.

The project includes:
- Analytical derivation of SVM formulations
- Manual and coded SVM solutions
- Static and adaptive RBF neural networks
- Performance evaluation and model comparison

All implementations are provided in a **Google Colab notebook**, and all theoretical explanations are documented in a **formal written report**.

---

## ğŸ§° Tools & Libraries

- **Python**
- **NumPy**
- **Matplotlib**
- **Scikit-learn**
- **Google Colab**

---

## ğŸ“‚ Repository Structure

```
.
â”œâ”€â”€ MP2 (1).pdf
â”‚   â””â”€â”€ Complete written report (theory, derivations, explanations)
â”‚
â”œâ”€â”€ Mini_Project_2.ipynb
â”‚   â””â”€â”€ Google Colab notebook with implementations and experiments
â”‚
â”œâ”€â”€ README.md
â”‚   â””â”€â”€ Project documentation
```

---

## ğŸ§© Project Content Overview

### ğŸ”¹ Question 1 â€“ Hard-Margin SVM
- Primal and dual formulations
- Margin derivation
- Support vectors and KKT conditions

### ğŸ”¹ Question 2 â€“ Soft-Margin SVM (â„“1 Slack)
- Hinge loss and slack variables
- Effect of regularization parameter **C**

### ğŸ”¹ Question 3 â€“ â„“2 Soft-Margin SVM
- â„“2 regularization
- Kernel validity and PSD condition

### ğŸ”¹ Question 4 â€“ Manual Hard-Margin SVM in â„Â²
- Hyperplane, margin, and support vectors

### ğŸ”¹ Question 5 â€“ Nonlinear Classification
- Model selection and limitations

### ğŸ”¹ Question 6 â€“ Radial Basis Function Neural Networks
- Static RBFNN
- Adaptive RBFNN (M-RAN Inspired)

### ğŸ”¹ Question 7 â€“ Linear SVM Implementation
- Parameter study and performance analysis

---

## ğŸ“Š Key Results

- Adaptive RBFNN achieves lower RMSE with fewer neurons.
- Linear SVM performs strongly on near-linearly separable data.
- Parameter **C** significantly impacts generalization.

---

## ğŸš€ How to Run

1. Open the notebook in Google Colab:
   ```
   Mini_Project_2.ipynb
   ```
2. Run all cells sequentially.

---

## ğŸ“„ Report

ğŸ“˜ **MP2 (1).pdf**

---

## ğŸ”— Links

- Google Colab Notebook:  
  https://colab.research.google.com/drive/1q1Lo1PNDZVKUzfceOROzuBnYmNYeSRcf

- GitHub Repository:  
  https://github.com/alisoltani1383/Fundamental-of-Intelligent-Systems-2025

---

## ğŸ§  Learning Outcomes

- Understand SVM theory and implementation
- Design static and adaptive RBF networks
- Analyze and interpret model performance

---

## âš ï¸ Notes

This repository is intended for **academic and educational purposes only**.
